{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32069,
     "status": "ok",
     "timestamp": 1611740282823,
     "user": {
      "displayName": "A V",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "UgM7VEXCdbTX",
    "outputId": "3bbb3f48-ad2b-4c8c-f6da-58c90565114d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1BTTm7E7hz51"
   },
   "outputs": [],
   "source": [
    "url_train_dev = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vSZRYmir99b4BqU9UwkJvVIJRBCVgbMye_zDzHwvtjFhvQYJXk9Q3q-spYGse0B5kgVWbEDuxiineIn/pub?gid=1591461788&single=true&output=csv'\n",
    "\n",
    "#url_test = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vT-KNR9nuYatLkSbzSRgpz6Ku1n4TN4w6kKmFLkA6QJHTfQzmX0puBsLF7PAAQJQAxUpgruDd_RRgK7/pub?gid=417546901&single=true&output=tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEtmPp7epxEZ"
   },
   "source": [
    "# Load and inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5D8w9zd1c2IJ"
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "def load_dataset(url):\n",
    "    r = requests.get(url_train_dev)\n",
    "    data = r.content.decode('utf8')\n",
    "    df = pd.read_csv(StringIO(data))\n",
    "    df.columns = ['bug-id', 'bug', 'label']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "executionInfo": {
     "elapsed": 2147,
     "status": "error",
     "timestamp": 1611740447220,
     "user": {
      "displayName": "A V",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "foL-QtlJItoR",
    "outputId": "1bb387d8-6468-4e6b-ec3a-18a43734754d"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['6784'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2fb0ea385cb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'bug-id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bug'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4172\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4174\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4175\u001b[0m         )\n\u001b[0;32m   4176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3885\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3886\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3887\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3889\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3920\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3921\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5283\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5284\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5285\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['6784'] not found in axis\""
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "data = \"C:/Users/David/Documents/GitHub/Data_Science_for_Software_Engineering/Project/bug_list.csv\"\n",
    "\n",
    "#r = requests.get(url_train_dev)\n",
    "#data = r.content.decode('utf8')\n",
    "df = pd.read_csv(data)\n",
    "for el in df:\n",
    "  if len(el) > 3:\n",
    "    df.drop(el)\n",
    "df.columns = ['bug-id', 'bug', 'label']\n",
    "print(df.head(100))\n",
    "df.head(100)\n",
    "df_train_dev = df[:7000]\n",
    "df_test = df[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 797,
     "status": "ok",
     "timestamp": 1606833990231,
     "user": {
      "displayName": "Andrina Vincenz",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "KWTvXPPgiDzU",
    "outputId": "58b45ee4-6195-4fda-f8ee-ad36a88ef6c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infos train-dev-set:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000 entries, 0 to 6999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   bug-id  7000 non-null   int64 \n",
      " 1   bug     7000 non-null   object\n",
      " 2   label   7000 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 164.2+ KB\n",
      "None\n",
      "Infos test-set:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2974 entries, 7000 to 9973\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   bug-id  2974 non-null   int64 \n",
      " 1   bug     2974 non-null   object\n",
      " 2   label   2974 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 69.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Infos train-dev-set:')\n",
    "print(df_train_dev.info())\n",
    "print('Infos test-set:')\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 982,
     "status": "ok",
     "timestamp": 1606833078025,
     "user": {
      "displayName": "Andrina Vincenz",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "h8lCjkb_kSOp",
    "outputId": "53afd811-d87c-47a0-a097-486927bf19c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bug-id</th>\n",
       "      <th>bug</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8166</td>\n",
       "      <td>need to clean up bidi reorder code</td>\n",
       "      <td>blocker\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9574</td>\n",
       "      <td>errno symbols are not always unique on AIX</td>\n",
       "      <td>blocker\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163123</td>\n",
       "      <td>Crash in [@ mozilla::dom::ClientSource::Window...</td>\n",
       "      <td>blocker\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32333</td>\n",
       "      <td>nsExtensionManager.js should get the XPCOM ABI...</td>\n",
       "      <td>blocker\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47872</td>\n",
       "      <td>NSS build fails on Windows since 20090213.1 ni...</td>\n",
       "      <td>blocker\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bug-id                                                bug     label\n",
       "0    8166                 need to clean up bidi reorder code  blocker\"\n",
       "1    9574         errno symbols are not always unique on AIX  blocker\"\n",
       "2  163123  Crash in [@ mozilla::dom::ClientSource::Window...  blocker\"\n",
       "3   32333  nsExtensionManager.js should get the XPCOM ABI...  blocker\"\n",
       "4   47872  NSS build fails on Windows since 20090213.1 ni...  blocker\""
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 798,
     "status": "ok",
     "timestamp": 1606833080607,
     "user": {
      "displayName": "Andrina Vincenz",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "p-K1HUEordhz",
    "outputId": "2b8d17c7-2175-4319-abd7-99f06d88e3b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blocker\"' 'critical\"' 'major\"' 'normal\"']\n"
     ]
    }
   ],
   "source": [
    "print(df_train_dev.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "executionInfo": {
     "elapsed": 883,
     "status": "ok",
     "timestamp": 1606833085359,
     "user": {
      "displayName": "Andrina Vincenz",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "mok54OinmXQw",
    "outputId": "19408f86-6111-403b-cd7f-9939b3d3eb70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd686c589e8>"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_dev.groupby('label').size().sort_values(ascending = False).plot.bar(figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1606833090290,
     "user": {
      "displayName": "Andrina Vincenz",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "3f24YMQAz44u",
    "outputId": "dcbfaa26-7282-4c2d-adc5-4200126d9ab2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "normal\"      7105\n",
       "critical\"    1875\n",
       "major\"        748\n",
       "blocker\"      246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dev.groupby('label').size().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qxb9qeRprB8"
   },
   "source": [
    "# Process labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FwgxNUdngK1"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_fitted = LabelEncoder().fit(df_train_dev['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5098,
     "status": "ok",
     "timestamp": 1606834052936,
     "user": {
      "displayName": "Andrina Vincenz",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "2V6JkOLrn-75",
    "outputId": "bc49349d-2fd2-483d-a8ec-725f0a6cbffe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# map all classes that are not in train_dev to undefined\n",
    "for i, label in enumerate(df_test['label']):\n",
    "    df_test['label'][i] = 'und' if label not in le_fitted.classes_ else label\n",
    "# check if it worked: should return an empty list\n",
    "print([label for label in df_test['label'] if label not in set(df_train_dev['label'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "executionInfo": {
     "elapsed": 643,
     "status": "error",
     "timestamp": 1606835043125,
     "user": {
      "displayName": "David Stalder",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsijLpQ4SIyqjTTwo8axfuAd0nTgHsTIdHbhLpSQ=s64",
      "userId": "06489165530893587391"
     },
     "user_tz": -60
    },
    "id": "Y4mGBukF1Dzu",
    "outputId": "77edc40d-ed9f-4a69-e5af-65b0f97d68c1"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7a6401a2cc1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train_dev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "df_train_dev['label'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EV6KmRn4oOIF"
   },
   "outputs": [],
   "source": [
    "y_train_dev, y_test = le_fitted.transform(df_train_dev['label']), le_fitted.transform(df_test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0gShv_UsLiZ"
   },
   "source": [
    "# Preprocess bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93UMrd5BtL-B"
   },
   "source": [
    "Pipeline classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6iOls7ib_-H"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "class TweetNormalizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "\n",
    "    def _normalize_tweet(self, tweet):\n",
    "        \"\"\"Remove punctuation and newlines, lowercase, pad with spaces.\n",
    "\n",
    "        :param tweet: string\n",
    "        :return: normalized string\n",
    "        \"\"\"\n",
    "        tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "        tweet = re.sub(r'\\n', r'', tweet)\n",
    "        tweet = tweet.lower()\n",
    "        tweet = re.sub(r'@\\w+\\b', r'', tweet)\n",
    "        tweet = re.sub(r'\\b\\S+//\\S+\\b', r'', tweet)\n",
    "        # tweet = ' ' + tweet + ' '\n",
    "        return tweet\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        tweets = []\n",
    "        for tweet in X:\n",
    "            tweets.append(self._normalize_tweet(tweet))\n",
    "        return np.array(tweets)\n",
    "\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "\n",
    "    vowels = set([c for c in 'aeiouäöüàéèëï'])\n",
    "    consonants = set([c for c in 'bcdfghklmnlpqrstvwxyz'])\n",
    "\n",
    "    def __init__(self):\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def _to_bigrams(self, tweet):\n",
    "        return [bg[0] + bg[1] for bg in zip(tweet, tweet[1:])]\n",
    "\n",
    "    def _get_vowel_consonant_ratio(self, tweet):\n",
    "        vf = 0\n",
    "        cf = 0\n",
    "        for c in tweet.lower():\n",
    "            if c in self.vowels:\n",
    "                vf =+ 1\n",
    "            elif c in self.consonants:\n",
    "                cf += 1\n",
    "        return vf / (cf + 1)\n",
    "\n",
    "    def _get_capitalization_ratio(self, tweet):\n",
    "        up_count = 0\n",
    "        for c in tweet:\n",
    "            if c.upper() == c:\n",
    "                up_count += 1\n",
    "        return up_count / (len(tweet) + 1)\n",
    "\n",
    "    def _get_double_char_freq(self, tweet):\n",
    "        double_freq = 0\n",
    "        for bg in self._to_bigrams(tweet):\n",
    "            if bg[0] == bg[1]:\n",
    "                double_freq += 1\n",
    "        return double_freq\n",
    "    \n",
    "    def _extract_num_features(self, tweets):\n",
    "        num_features = []\n",
    "        for tweet in tweets:\n",
    "            feat_tweet = []\n",
    "            feat_tweet.append(self._get_vowel_consonant_ratio(tweet))\n",
    "            feat_tweet.append(self._get_capitalization_ratio(tweet))\n",
    "            feat_tweet.append(self._get_double_char_freq(tweet))\n",
    "            num_features.append(feat_tweet)\n",
    "        return np.array(num_features)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        numerical_features = self._extract_num_features(X)\n",
    "        self.scaler.fit(numerical_features)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        numerical_features= self._extract_num_features(X)\n",
    "        return X, self.scaler.transform(numerical_features)\n",
    "\n",
    "\n",
    "class MatrixToArrayConverter1(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[0].toarray(), X[1]\n",
    "\n",
    "\n",
    "class MatrixUnifier(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return np.concatenate([X[0].todense(), X[1]], axis=1)\n",
    "\n",
    "\n",
    "class CountVectorizerWrapper:\n",
    "\n",
    "    def __init__(self, ngram_range, analyzer, max_features, binary):\n",
    "        print('args:', str([ngram_range, analyzer, max_features, binary]))\n",
    "        self.countvec = CountVectorizer(ngram_range=ngram_range, analyzer=analyzer, max_features=max_features, binary=binary)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        tweets, numerical_features = X\n",
    "        self.countvec.fit(tweets)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        tweets, numerical_features = X\n",
    "        return self.countvec.transform(tweets), numerical_features\n",
    "\n",
    "\n",
    "class OneHotEncoderWrapper:\n",
    "\n",
    "    def __init__(self, handle_unknown):\n",
    "        self.ohe = OneHotEncoder(handle_unknown=handle_unknown)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.ohe.fit(X[0])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.ohe.transform(X[0]), X[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3gvmuUPtS5j"
   },
   "source": [
    "Helper classes for the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asuv2Ey8suTF"
   },
   "outputs": [],
   "source": [
    "class GenericClassifier(BaseEstimator):\n",
    "\n",
    "    def __init__(self, estimator):\n",
    "        self.clf = clf\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.clf.fit(X, y)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n",
    "\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.clf.score(X, y)\n",
    "\n",
    "\n",
    "class Debug(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, X):\n",
    "        import pdb; pdb.set_trace()\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yerRC06qtabm"
   },
   "source": [
    "# GridSearch and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQq5eigQKi2D"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pDxK9slayq3"
   },
   "outputs": [],
   "source": [
    "clf_param_grid = {\n",
    "    'MultinomialNB': [MultinomialNB, {'CLF__alpha': [0.1, 1]}],\n",
    "    'SGDClassifier': [SGDClassifier, {'CLF__loss': ['hinge', 'log'], 'CLF__penalty': ['l2', 'l1'], 'CLF__max_iter': [100, 300], 'CLF__early_stopping': [True, False]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 427145,
     "status": "ok",
     "timestamp": 1606834879735,
     "user": {
      "displayName": "Andrina Vincenz",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "YOsRd7OoFUWn",
    "outputId": "1f616e78-2bbd-42bc-febe-97dd7bd2b30c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "MultinomialNB\n",
      "{'CLF__alpha': [0.1, 1]}\n",
      "args: [(2, 2), 'char_wb', 100, True]\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.5s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "------------------------------\n",
      "SGDClassifier\n",
      "{'CLF__loss': ['hinge', 'log'], 'CLF__penalty': ['l2', 'l1'], 'CLF__max_iter': [100, 300], 'CLF__early_stopping': [True, False]}\n",
      "args: [(2, 2), 'char_wb', 100, True]\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.5s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   1.0s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   4.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.5s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   3.0s\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for clf_name in clf_param_grid:\n",
    "    print(30*'-')\n",
    "    print(clf_name)\n",
    "    param_grid = clf_param_grid[clf_name][1]\n",
    "    print(param_grid)\n",
    "    bigram_vec_args = dict(ngram_range=(2,2), analyzer='char_wb', max_features=100, binary=True)\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('TweetNormalizer', TweetNormalizer()),\n",
    "        ('FeatureExtractor', FeatureExtractor()),\n",
    "        ('BigramVectorizer', CountVectorizerWrapper(**bigram_vec_args)),\n",
    "        ('MatrixToArrayConverter', MatrixToArrayConverter1()),\n",
    "        ('OneHotEncoder', OneHotEncoderWrapper(handle_unknown='ignore')),\n",
    "        ('MatrixUnifier', MatrixUnifier()),\n",
    "        ('CLF', clf_param_grid[clf_name][0]())\n",
    "    ], verbose=True)\n",
    "    grid = GridSearchCV(pipe, n_jobs=1, param_grid=param_grid, scoring='f1_micro', cv=10)\n",
    "    grid.fit(df_train_dev['bug'].to_numpy(), y_train_dev)\n",
    "    models.append(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aA3JAYJBDZxy"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZHDby7NB7PW"
   },
   "source": [
    "Micro f1-Score of the naive base models on the dev set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1606835092076,
     "user": {
      "displayName": "Andrina Vincenz",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "gDOlBtb2B4Nq",
    "outputId": "0389548c-2721-41d4-dc94-2df01b8de92c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.12249234, 1.1144706 ]),\n",
       " 'mean_score_time': array([0.12933674, 0.12165906]),\n",
       " 'mean_test_score': array([0.72385714, 0.72357143]),\n",
       " 'param_CLF__alpha': masked_array(data=[0.1, 1],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'CLF__alpha': 0.1}, {'CLF__alpha': 1}],\n",
       " 'rank_test_score': array([1, 2], dtype=int32),\n",
       " 'split0_test_score': array([0.72714286, 0.72714286]),\n",
       " 'split1_test_score': array([0.72142857, 0.72142857]),\n",
       " 'split2_test_score': array([0.7       , 0.70142857]),\n",
       " 'split3_test_score': array([0.71571429, 0.71571429]),\n",
       " 'split4_test_score': array([0.72857143, 0.72857143]),\n",
       " 'split5_test_score': array([0.73285714, 0.73285714]),\n",
       " 'split6_test_score': array([0.71714286, 0.71714286]),\n",
       " 'split7_test_score': array([0.71714286, 0.71714286]),\n",
       " 'split8_test_score': array([0.73857143, 0.73714286]),\n",
       " 'split9_test_score': array([0.74      , 0.73714286]),\n",
       " 'std_fit_time': array([0.02722769, 0.01921792]),\n",
       " 'std_score_time': array([0.02204268, 0.00362002]),\n",
       " 'std_test_score': array([0.01150067, 0.01063782])}"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcqrfTK1Bcxd"
   },
   "source": [
    "Micro and macro f1-score of the best naive bayes model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1606835105102,
     "user": {
      "displayName": "Andrina Vincenz",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "eIlAIaVnNHOU",
    "outputId": "a0323b54-78ef-42eb-c0b9-64f6e45ae3b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro-score on the testset: 0.8809683927370545\n",
      "F1-macro-score on the testset: 0.23417947801215588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "preds = models[0].predict(df_test['bug'].to_numpy())\n",
    "f1_micro = f1_score(preds, y_test, average='micro')\n",
    "f1_macro = f1_score(preds, y_test, average='macro')\n",
    "print(f'F1-micro-score on the testset: {f1_micro}')\n",
    "print(f'F1-macro-score on the testset: {f1_macro}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RKO1bbsCDne"
   },
   "source": [
    "Micro f1-Score of the SGD models on the dev set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 929,
     "status": "ok",
     "timestamp": 1606835113536,
     "user": {
      "displayName": "Andrina Vincenz",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "FW-5WG9SBzyU",
    "outputId": "e5bde2da-07eb-487c-99fd-9f1b0b3c40e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.3469048 , 1.56157084, 1.33405526, 1.59170597, 1.4405201 ,\n",
       "        1.72794034, 1.44879322, 1.713466  , 2.22032859, 3.28094015,\n",
       "        2.58390758, 3.05967634, 2.83111517, 4.57194583, 3.0159354 ,\n",
       "        4.27098441]),\n",
       " 'mean_score_time': array([0.12111337, 0.12070925, 0.12135096, 0.12362285, 0.12067373,\n",
       "        0.12134085, 0.12401848, 0.12226448, 0.06814857, 0.06908364,\n",
       "        0.06998861, 0.0694267 , 0.06960695, 0.0790782 , 0.06847961,\n",
       "        0.06860471]),\n",
       " 'mean_test_score': array([0.65785714, 0.67328571, 0.67057143, 0.69542857, 0.65142857,\n",
       "        0.65142857, 0.63114286, 0.61928571, 0.72014286, 0.69928571,\n",
       "        0.71814286, 0.69571429, 0.713     , 0.72585714, 0.71357143,\n",
       "        0.71228571]),\n",
       " 'param_CLF__early_stopping': masked_array(data=[True, True, True, True, True, True, True, True, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_CLF__loss': masked_array(data=['hinge', 'hinge', 'hinge', 'hinge', 'log', 'log',\n",
       "                    'log', 'log', 'hinge', 'hinge', 'hinge', 'hinge',\n",
       "                    'log', 'log', 'log', 'log'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_CLF__max_iter': masked_array(data=[100, 100, 300, 300, 100, 100, 300, 300, 100, 100, 300,\n",
       "                    300, 100, 100, 300, 300],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_CLF__penalty': masked_array(data=['l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l1'}],\n",
       " 'rank_test_score': array([12, 10, 11,  9, 13, 13, 15, 16,  2,  7,  3,  8,  5,  1,  4,  6],\n",
       "       dtype=int32),\n",
       " 'split0_test_score': array([0.60857143, 0.59285714, 0.67285714, 0.66428571, 0.72      ,\n",
       "        0.72714286, 0.66571429, 0.70428571, 0.73428571, 0.70142857,\n",
       "        0.71714286, 0.71285714, 0.73428571, 0.72714286, 0.62857143,\n",
       "        0.71428571]),\n",
       " 'split1_test_score': array([0.70714286, 0.73714286, 0.59428571, 0.68285714, 0.71      ,\n",
       "        0.48714286, 0.41714286, 0.53857143, 0.72714286, 0.68285714,\n",
       "        0.74571429, 0.45428571, 0.73285714, 0.74      , 0.74      ,\n",
       "        0.74      ]),\n",
       " 'split2_test_score': array([0.64571429, 0.59714286, 0.70142857, 0.67142857, 0.64      ,\n",
       "        0.68      , 0.64714286, 0.52285714, 0.71285714, 0.68285714,\n",
       "        0.66571429, 0.70571429, 0.66571429, 0.71142857, 0.71      ,\n",
       "        0.68428571]),\n",
       " 'split3_test_score': array([0.66857143, 0.67571429, 0.63571429, 0.72571429, 0.58428571,\n",
       "        0.67571429, 0.68428571, 0.54285714, 0.71571429, 0.54857143,\n",
       "        0.69714286, 0.72714286, 0.72571429, 0.72142857, 0.70428571,\n",
       "        0.73      ]),\n",
       " 'split4_test_score': array([0.70714286, 0.68857143, 0.55428571, 0.68      , 0.41857143,\n",
       "        0.69714286, 0.69857143, 0.67428571, 0.71571429, 0.72428571,\n",
       "        0.72571429, 0.71857143, 0.71      , 0.72857143, 0.73571429,\n",
       "        0.72857143]),\n",
       " 'split5_test_score': array([0.71142857, 0.69      , 0.73428571, 0.68571429, 0.71      ,\n",
       "        0.58714286, 0.63571429, 0.65714286, 0.69857143, 0.73714286,\n",
       "        0.73714286, 0.73857143, 0.65142857, 0.70142857, 0.73714286,\n",
       "        0.69285714]),\n",
       " 'split6_test_score': array([0.50142857, 0.70857143, 0.69714286, 0.72571429, 0.71857143,\n",
       "        0.71      , 0.67142857, 0.69571429, 0.73142857, 0.72714286,\n",
       "        0.69714286, 0.74      , 0.73142857, 0.72285714, 0.73142857,\n",
       "        0.65714286]),\n",
       " 'split7_test_score': array([0.64428571, 0.66428571, 0.68857143, 0.71285714, 0.62428571,\n",
       "        0.71285714, 0.59      , 0.68571429, 0.71142857, 0.72285714,\n",
       "        0.72714286, 0.72      , 0.71142857, 0.72285714, 0.72428571,\n",
       "        0.71428571]),\n",
       " 'split8_test_score': array([0.70857143, 0.70285714, 0.69857143, 0.68714286, 0.69571429,\n",
       "        0.49142857, 0.66714286, 0.49142857, 0.72857143, 0.71285714,\n",
       "        0.73142857, 0.74142857, 0.73857143, 0.73      , 0.67857143,\n",
       "        0.73      ]),\n",
       " 'split9_test_score': array([0.67571429, 0.67571429, 0.72857143, 0.71857143, 0.69285714,\n",
       "        0.74571429, 0.63428571, 0.68      , 0.72571429, 0.75285714,\n",
       "        0.73714286, 0.69857143, 0.72857143, 0.75285714, 0.74571429,\n",
       "        0.73142857]),\n",
       " 'std_fit_time': array([0.05205755, 0.0342076 , 0.03620121, 0.02913184, 0.03956723,\n",
       "        0.04469902, 0.04585984, 0.03530371, 0.05321906, 0.32119413,\n",
       "        0.10546443, 0.19835106, 0.06737777, 0.55668779, 0.16551701,\n",
       "        0.31385191]),\n",
       " 'std_score_time': array([0.00306016, 0.00229236, 0.00225608, 0.00421803, 0.00126853,\n",
       "        0.00202035, 0.00462066, 0.0034264 , 0.00098812, 0.00243849,\n",
       "        0.00325373, 0.00235298, 0.00233731, 0.02118893, 0.00078493,\n",
       "        0.00058814]),\n",
       " 'std_test_score': array([0.06161517, 0.04366874, 0.05545434, 0.02186041, 0.0890769 ,\n",
       "        0.09057864, 0.07698078, 0.0797656 , 0.01054533, 0.05450051,\n",
       "        0.02329973, 0.08165632, 0.02878102, 0.01340804, 0.03429315,\n",
       "        0.02497509])}"
      ]
     },
     "execution_count": 130,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlY-SAdYBmty"
   },
   "source": [
    "Accuracy of the best SGD model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1606835123513,
     "user": {
      "displayName": "Andrina Vincenz",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "PEm-z0w3NiBf",
    "outputId": "170c4845-ac41-481f-edf7-bb14749328e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro-score on the testset: 0.9435104236718225\n",
      "F1-macro-score on the testset: 0.24273356401384086\n"
     ]
    }
   ],
   "source": [
    "preds = models[1].predict(df_test['bug'].to_numpy())\n",
    "f1_micro = f1_score(preds, y_test, average='micro')\n",
    "f1_macro = f1_score(preds, y_test, average='macro')\n",
    "print(f'F1-micro-score on the testset: {f1_micro}')\n",
    "print(f'F1-macro-score on the testset: {f1_macro}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kqDIw95Nsr2"
   },
   "source": [
    "Let's check the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "executionInfo": {
     "elapsed": 1127,
     "status": "ok",
     "timestamp": 1606835132321,
     "user": {
      "displayName": "Andrina Vincenz",
      "photoUrl": "",
      "userId": "08102926501889083799"
     },
     "user_tz": -60
    },
    "id": "Xeb6jHmeAeVK",
    "outputId": "30e164f5-f8b6-43f5-b02d-c5fac3747d8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blocker\"</th>\n",
       "      <th>critical\"</th>\n",
       "      <th>major\"</th>\n",
       "      <th>normal\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blocker\"</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critical\"</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>major\"</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal\"</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           blocker\"  critical\"  major\"  normal\"\n",
       "blocker\"          0          0       0        1\n",
       "critical\"         0          0       0      144\n",
       "major\"            0          0       0       23\n",
       "normal\"           0          0       0     2806"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(le_fitted.classes_)\n",
    "def create_confusion_matrix(num_classes, preds, y_test):\n",
    "    \"\"\"Create confusion matrix 'by hand' since test set does not contain all labels (thanks to Sarah Kiener).\"\"\"\n",
    "    df = pd.DataFrame(np.zeros((num_classes, num_classes), dtype=int))\n",
    "    for i, j in zip(preds, y_test):\n",
    "        df.iloc[i, j] += 1\n",
    "    df.columns = le_fitted.classes_\n",
    "    df.index = le_fitted.classes_\n",
    "    return df\n",
    "df = create_confusion_matrix(num_classes, preds, y_test)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dataseminar.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
